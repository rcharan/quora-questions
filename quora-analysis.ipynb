{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "import sklearn.decomposition           as sk_decomp\n",
    "import sklearn.model_selection         as sk_cv\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question\n",
       "0  What is the step by step guide to invest in sh...\n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
       "2  How can I increase the speed of my internet co...\n",
       "3  Why am I mentally very lonely? How can I solve...\n",
       "4  Which one dissolve in water quikly sugar, salt..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora = pd.read_csv('quora_questions.csv')\n",
    "quora.rename(lambda x : x.lower(), axis = 'columns', inplace = True)\n",
    "quora.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Simplest option first: Count Vectorizer to create term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.8 µs ± 389 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer: uses spaCy tokenizer, then removes punctuation and stop words, then finally casts\n",
    "bad_predicates = [\n",
    "    lambda token : token.is_stop,\n",
    "    lambda token : token.text in string.punctuation\n",
    "]\n",
    "\n",
    "filter_tokenizer = lmap_filter(\n",
    "    lambda t : t.lower_,\n",
    "    no_predicates(*bad_predicates),\n",
    ")\n",
    "\n",
    "spacy_tokenizer = spacy.load(\"en_core_web_sm\", disable=['tagger', 'parser', 'ner'])\n",
    "\n",
    "tokenizer       = compose(filter_tokenizer, spacy_tokenizer)\n",
    "\n",
    "# Disabling most spaCy features leads to decent tokenizer performance \n",
    "#  For comparison you can try un-disabling tagging\n",
    "%timeit tokenizer(quora.question[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.724 seconds elapsed\n",
      "14744 word identified with the given frequency cutoffs\n"
     ]
    }
   ],
   "source": [
    "count_vectorizor = sk_text.CountVectorizer(\n",
    "                       strip_accents= 'unicode', \n",
    "                       lowercase    = True,\n",
    "                       analyzer     = tokenizer,\n",
    "                       max_df       = 0.9,\n",
    "                       min_df       = 10\n",
    ")\n",
    "\n",
    "Timer.start()\n",
    "X = count_vectorizor.fit_transform(quora.question)\n",
    "Timer.end()\n",
    "print(f'{X.shape[1]} word identified with the given frequency cutoffs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Modelling\n",
    "\n",
    "#### TASK: Using Scikit-Learn create an instance of LDA. \n",
    "\n",
    "- You can manually run and tune your model, then evaluate the resulting clusters. \n",
    "- Or you can use gridsearch to try and identify the best number of topics to use. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from disk\n",
      "642.725 seconds elapsed in original fitting\n"
     ]
    }
   ],
   "source": [
    "learner = sk_decomp.LatentDirichletAllocation(n_jobs = -1, verbose = 1, random_state = 42)\n",
    "model, model_data = fit_or_load_model(learner, X, 'simple-lda', force_fit = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = sk_decomp.LatentDirichletAllocation(n_jobs = -1, verbose = 1, random_state = 42)\n",
    "param_grid = {'n_components': [15, 20, 25],'learning_decay': [.5, .7]}\n",
    "splitter = sk_cv.KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "model = sk_cv.GridSearchCV(learner, param_grid, verbose = 2, cv = splitter)\n",
    "model, model_data = fit_or_load_model(model, X, 'simple-lda-grid', force_fit = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Evaluate the different models you have run and determine which model you think determines the best clusters.  \n",
    "\n",
    "\n",
    "The evaluation part could invlove:\n",
    "- Printing out the top 15 most common words for each of the topics and seeing if they make sense.\n",
    "- Using the perplexity and log-likelihoood scores.\n",
    "- Using the pyLDAvis tool to investigate the different clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TASK: Add a new column to the original quora dataframe that labels each question into one of the topic categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
